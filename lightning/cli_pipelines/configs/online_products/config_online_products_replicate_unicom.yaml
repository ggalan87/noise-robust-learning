seed_everything: 1024
data:
  class_path: lightning.data.datamodules.OnlineProductsDataModule
  init_args:
    data_dir: "/data/datasets"
    batch_size: 64
    train_transforms: lightning.data.default_transforms.OnlineProductsClipTrainTransforms
    val_transforms: lightning.data.default_transforms.OnlineProductsClipTestTransforms
    test_transforms: lightning.data.default_transforms.OnlineProductsClipTestTransforms
    val_split: 0.0
    num_workers: 7
    dataset_args:
      class_path: lightning.data.datamodules.OnlineProductsArgs
      init_args:
        training_variant: null
sampler:
  class_path: torch.utils.data.RandomSampler
  init_args:
    replacement: False
    num_samples: null
model:
  class_path: lightning.models.LitUnicom
  init_args:
    num_channels: 3
    use_pretrained_weights: True
    optimizer_class: torch.optim.AdamW
    optimizer_kwargs:
      lr: 3e-05
      weight_decay: 0
    scheduler_class: torch.optim.lr_scheduler.OneCycleLR
    scheduler_kwargs:
      interval: "step"
      pct_start: 0.1
    loss_class: pytorch_metric_learning.losses.ArcFaceLoss
    loss_kwargs:
      margin: 14.4
      scale: 32
      optimizer_kwargs:
        lr: 3e-04
    miner_class: null
    miner_kwargs: null
    noise_reducer_class: null
    noise_reducer_kwargs: null
    model_variant: "ViT-B/32"
trainer:
  max_epochs: 64
  accelerator: 'gpu'
  logger:
    class_path: pytorch_lightning.loggers.TensorBoardLogger
    init_args:
      save_dir: "./lightning_logs"
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: "step"
    - class_path: lightning.ext.PeriodicCheckpoint
      init_args:
        every: 1